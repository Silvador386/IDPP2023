{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# [IDPP CLEF Challlenge](http://brainteaser.dei.unipd.it/challenges/idpp2023/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "import lightgbm\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import r_regression\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET_DIR = \"../data/datasetA_train\"\n",
    "ID_FEAT = \"patient_id\"\n",
    "\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filenames_in_folder(dir_path):\n",
    "    file_names = []\n",
    "    for _, __, f_names in os.walk(dir_path):\n",
    "        for file_name in f_names:\n",
    "            file_names.append(file_name)\n",
    "        break\n",
    "    return file_names\n",
    "\n",
    "\n",
    "def read_dfs(dir_path):\n",
    "    file_names = filenames_in_folder(dir_path)\n",
    "    dfs = {file_name.removesuffix(\".csv\"): pd.read_csv(os.path.join(dir_path, file_name)) for file_name in file_names if file_name.endswith(\"csv\")}\n",
    "    return dfs\n",
    "\n",
    "dfs = read_dfs(DATASET_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unique patients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>datasetA_train-edss</th>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datasetA_train-evoked-potentials</th>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datasetA_train-mri</th>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datasetA_train-ms-type</th>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datasetA_train-outcomes</th>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datasetA_train-relapses</th>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datasetA_train-static-vars</th>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Unique patients\n",
       "datasetA_train-edss                           439\n",
       "datasetA_train-evoked-potentials              153\n",
       "datasetA_train-mri                            279\n",
       "datasetA_train-ms-type                        210\n",
       "datasetA_train-outcomes                       440\n",
       "datasetA_train-relapses                       259\n",
       "datasetA_train-static-vars                    440"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dfs_unique_patients(dfs):\n",
    "    out = {}\n",
    "    for name, df in dfs.items():\n",
    "        out[name] = len(df[ID_FEAT].unique())\n",
    "    return pd.DataFrame.from_dict(out, orient=\"index\", columns=[\"Unique patients\"])\n",
    "unique_patients = dfs_unique_patients(dfs)\n",
    "unique_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_df = pd.merge(dfs[\"datasetA_train-static-vars\"], dfs[\"datasetA_train-outcomes\"],\n",
    "                         on=\"patient_id\", how=\"outer\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{int64: ['delta_relapse_time0'], object: ['patient_id', 'centre']}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['centre'], dtype='object')] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[20], line 66\u001B[0m\n\u001B[0;32m     63\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m merged_df\n\u001B[0;32m     65\u001B[0m dfs \u001B[38;5;241m=\u001B[39m read_dfs(DATASET_DIR)\n\u001B[1;32m---> 66\u001B[0m \u001B[43mmerge_dfs_complete\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdfs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[20], line 33\u001B[0m, in \u001B[0;36mmerge_dfs_complete\u001B[1;34m(dfs)\u001B[0m\n\u001B[0;32m     30\u001B[0m     \u001B[38;5;66;03m# relapses_df = relapses_df.drop([\"centre\"], axis=1)\u001B[39;00m\n\u001B[0;32m     31\u001B[0m     relapses_df \u001B[38;5;241m=\u001B[39m group_df_by_patient_id(relapses_df, ID_FEAT, ts_feats, oo_feats)\n\u001B[1;32m---> 33\u001B[0m     \u001B[43mmerged_df\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcentre\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;66;03m#     ms_type_df = dfs[\"datasetA_train-ms-type.csv\"]\u001B[39;00m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;66;03m#     ts_feats = [\"multiple_sclerosis_type\", \"delta_observation_time0\"]\u001B[39;00m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;66;03m#     oo_feats = [\"centre\"]\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;66;03m#     oo_feats = [\"centre\"]\u001B[39;00m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;66;03m#     edss_df = transpose_df_by_uniques(edss_df, ID_FEAT, ts_feats, oo_feats)\u001B[39;00m\n\u001B[0;32m     57\u001B[0m     transposed_dfs \u001B[38;5;241m=\u001B[39m [relapses_df]\n",
      "File \u001B[1;32mc:\\programming\\python projects\\idpp2023\\idpp2023-kde-lab\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:1073\u001B[0m, in \u001B[0;36m_LocationIndexer.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1070\u001B[0m axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxis \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m   1072\u001B[0m maybe_callable \u001B[38;5;241m=\u001B[39m com\u001B[38;5;241m.\u001B[39mapply_if_callable(key, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj)\n\u001B[1;32m-> 1073\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmaybe_callable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\programming\\python projects\\idpp2023\\idpp2023-kde-lab\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:1301\u001B[0m, in \u001B[0;36m_LocIndexer._getitem_axis\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1298\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(key, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mndim\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m key\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   1299\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot index with multidimensional key\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1301\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_iterable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1303\u001B[0m \u001B[38;5;66;03m# nested tuple slicing\u001B[39;00m\n\u001B[0;32m   1304\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_nested_tuple(key, labels):\n",
      "File \u001B[1;32mc:\\programming\\python projects\\idpp2023\\idpp2023-kde-lab\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:1239\u001B[0m, in \u001B[0;36m_LocIndexer._getitem_iterable\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1236\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_key(key, axis)\n\u001B[0;32m   1238\u001B[0m \u001B[38;5;66;03m# A collection of keys\u001B[39;00m\n\u001B[1;32m-> 1239\u001B[0m keyarr, indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_listlike_indexer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1240\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_reindex_with_indexers(\n\u001B[0;32m   1241\u001B[0m     {axis: [keyarr, indexer]}, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, allow_dups\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1242\u001B[0m )\n",
      "File \u001B[1;32mc:\\programming\\python projects\\idpp2023\\idpp2023-kde-lab\\venv\\lib\\site-packages\\pandas\\core\\indexing.py:1432\u001B[0m, in \u001B[0;36m_LocIndexer._get_listlike_indexer\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1429\u001B[0m ax \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_get_axis(axis)\n\u001B[0;32m   1430\u001B[0m axis_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_get_axis_name(axis)\n\u001B[1;32m-> 1432\u001B[0m keyarr, indexer \u001B[38;5;241m=\u001B[39m \u001B[43max\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_indexer_strict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1434\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m keyarr, indexer\n",
      "File \u001B[1;32mc:\\programming\\python projects\\idpp2023\\idpp2023-kde-lab\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6070\u001B[0m, in \u001B[0;36mIndex._get_indexer_strict\u001B[1;34m(self, key, axis_name)\u001B[0m\n\u001B[0;32m   6067\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   6068\u001B[0m     keyarr, indexer, new_indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reindex_non_unique(keyarr)\n\u001B[1;32m-> 6070\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_if_missing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeyarr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   6072\u001B[0m keyarr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtake(indexer)\n\u001B[0;32m   6073\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Index):\n\u001B[0;32m   6074\u001B[0m     \u001B[38;5;66;03m# GH 42790 - Preserve name from an Index\u001B[39;00m\n",
      "File \u001B[1;32mc:\\programming\\python projects\\idpp2023\\idpp2023-kde-lab\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6130\u001B[0m, in \u001B[0;36mIndex._raise_if_missing\u001B[1;34m(self, key, indexer, axis_name)\u001B[0m\n\u001B[0;32m   6128\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m use_interval_msg:\n\u001B[0;32m   6129\u001B[0m         key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[1;32m-> 6130\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNone of [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] are in the [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maxis_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   6132\u001B[0m not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(ensure_index(key)[missing_mask\u001B[38;5;241m.\u001B[39mnonzero()[\u001B[38;5;241m0\u001B[39m]]\u001B[38;5;241m.\u001B[39munique())\n\u001B[0;32m   6133\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnot_found\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not in index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyError\u001B[0m: \"None of [Index(['centre'], dtype='object')] are in the [index]\""
     ]
    }
   ],
   "source": [
    "def merge_dfs_complete(dfs):\n",
    "    def change_ts_column_to_list(orig_df, id_feat, other_feature):\n",
    "        print(orig_df.columns.to_series().groupby(orig_df.dtypes).groups)\n",
    "        orig_df[other_feature] = pd.Series(orig_df.groupby(id_feat)[other_feature].apply(lambda x: x.values).values.tolist())\n",
    "        return orig_df\n",
    "    \n",
    "    def change_ts_column_same_values_to_one(orig_df, id_feat, other_feature):\n",
    "        orig_df[other_feature] = orig_df.groupby(id_feat)[other_feature].agg(pd.Series.mode)\n",
    "        return orig_df\n",
    "\n",
    "    def group_df_by_patient_id(orig_df, id_feat, time_series_feats, one_occurrence_feats):\n",
    "        for ts_feat in time_series_feats:\n",
    "            orig_df = change_ts_column_to_list(orig_df, id_feat, ts_feat)\n",
    "        \n",
    "        # for oo_feat in one_occurrence_feats:\n",
    "        #     orig_df = change_ts_column_same_values_to_one(orig_df, id_feat, ts_feat)\n",
    "#         ts_dfs = [change_ts_column_to_list(orig_df, id_feat, ts_feat) for ts_feat in time_series_feats]\n",
    "#         oo_dfs = [change_ts_column_same_values_to_one(orig_df, id_feat, oo_feat) for oo_feat in one_occurrence_feats]\n",
    "\n",
    "#         out_df = pd.concat([*oo_dfs, *ts_dfs], axis=1)\n",
    "        # out_df.reset_index(names=id_feat, inplace=True)\n",
    "        return orig_df\n",
    "    \n",
    "    merged_df = pd.merge(dfs[\"datasetA_train-static-vars\"], dfs[\"datasetA_train-outcomes\"],\n",
    "                         on=\"patient_id\", how=\"outer\")\n",
    "\n",
    "    relapses_df = dfs[\"datasetA_train-relapses\"]\n",
    "    ts_feats = [\"delta_relapse_time0\"]\n",
    "    oo_feats = []\n",
    "    # relapses_df = relapses_df.drop([\"centre\"], axis=1)\n",
    "    relapses_df = group_df_by_patient_id(relapses_df, ID_FEAT, ts_feats, oo_feats)\n",
    "    \n",
    "    merged_df.loc[[\"centre\"]]\n",
    "\n",
    "#     ms_type_df = dfs[\"datasetA_train-ms-type.csv\"]\n",
    "#     ts_feats = [\"multiple_sclerosis_type\", \"delta_observation_time0\"]\n",
    "#     oo_feats = [\"centre\"]\n",
    "#     ms_type_df = transpose_df_by_uniques(ms_type_df, ID_FEAT, ts_feats, oo_feats)\n",
    "\n",
    "#     mri_df = dfs[\"datasetA_train-mri.csv\"]\n",
    "#     ts_feats = [\"mri_area_label\", \"lesions_T1\", \"lesions_T1_gadolinium\", \"number_of_lesions_T1_gadolinium\",\n",
    "#                 \"new_or_enlarged_lesions_T2\", \"number_of_new_or_enlarged_lesions_T2\", \"lesions_T2\", \"number_of_total_lesions_T2\", \"delta_mri_time0\"]\n",
    "#     oo_feats = [\"centre\"]\n",
    "#     mri_df = transpose_df_by_uniques(mri_df, ID_FEAT, ts_feats, oo_feats)\n",
    "\n",
    "#     evoked_p_df = dfs[\"datasetA_train-evoked-potentials.csv\"]\n",
    "#     ts_feats = [\"altered_potential\", \"potential_value\", \"location\", \"delta_evoked_potential_time0\"]\n",
    "#     oo_feats = [\"centre\"]\n",
    "#     evoked_p_df = transpose_df_by_uniques(evoked_p_df, ID_FEAT, ts_feats, oo_feats)\n",
    "\n",
    "\n",
    "#     edss_df = dfs[\"datasetA_train-edss.csv\"]\n",
    "#     ts_feats = [\"edss_as_evaluated_by_clinician\", \"delta_edss_time0\"]\n",
    "#     oo_feats = [\"centre\"]\n",
    "#     edss_df = transpose_df_by_uniques(edss_df, ID_FEAT, ts_feats, oo_feats)\n",
    "\n",
    "    transposed_dfs = [relapses_df]\n",
    "    # print(relapses_df.columns.to_series().groupby(relapses_df.dtypes).groups)\n",
    "    # print(merged_df.columns.to_series().groupby(merged_df.dtypes).groups)\n",
    "    merged_df = pd.merge(merged_df, relapses_df, on=ID_FEAT, how=\"inner\")\n",
    "\n",
    "    # merged_df = merged_df.loc[:, ~merged_df.columns.duplicated()].copy()  # Removes duplicate patient_id, centre\n",
    "    return merged_df\n",
    "\n",
    "dfs = read_dfs(DATASET_DIR)\n",
    "merge_dfs_complete(dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}